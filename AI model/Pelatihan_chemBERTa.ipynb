{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f2a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be79b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:55:20.318893: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-21 18:55:20.932479: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-21 18:55:24.700758: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-21 18:55:26.116481: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec={'A': TensorSpec(shape=(), dtype=tf.float32, name=None), 'B': TensorSpec(shape=(), dtype=tf.float32, name=None), 'C': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cv': TensorSpec(shape=(), dtype=tf.float32, name=None), 'G': TensorSpec(shape=(), dtype=tf.float32, name=None), 'G_atomization': TensorSpec(shape=(), dtype=tf.float32, name=None), 'H': TensorSpec(shape=(), dtype=tf.float32, name=None), 'H_atomization': TensorSpec(shape=(), dtype=tf.float32, name=None), 'InChI': TensorSpec(shape=(), dtype=tf.string, name=None), 'InChI_relaxed': TensorSpec(shape=(), dtype=tf.string, name=None), 'Mulliken_charges': TensorSpec(shape=(29,), dtype=tf.float32, name=None), 'SMILES': TensorSpec(shape=(), dtype=tf.string, name=None), 'SMILES_relaxed': TensorSpec(shape=(), dtype=tf.string, name=None), 'U': TensorSpec(shape=(), dtype=tf.float32, name=None), 'U0': TensorSpec(shape=(), dtype=tf.float32, name=None), 'U0_atomization': TensorSpec(shape=(), dtype=tf.float32, name=None), 'U_atomization': TensorSpec(shape=(), dtype=tf.float32, name=None), 'alpha': TensorSpec(shape=(), dtype=tf.float32, name=None), 'charges': TensorSpec(shape=(29,), dtype=tf.int64, name=None), 'frequencies': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'gap': TensorSpec(shape=(), dtype=tf.float32, name=None), 'homo': TensorSpec(shape=(), dtype=tf.float32, name=None), 'index': TensorSpec(shape=(), dtype=tf.int64, name=None), 'lumo': TensorSpec(shape=(), dtype=tf.float32, name=None), 'mu': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_atoms': TensorSpec(shape=(), dtype=tf.int64, name=None), 'positions': TensorSpec(shape=(29, 3), dtype=tf.float32, name=None), 'r2': TensorSpec(shape=(), dtype=tf.float32, name=None), 'tag': TensorSpec(shape=(), dtype=tf.string, name=None), 'zpve': TensorSpec(shape=(), dtype=tf.float32, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "qm9 = tfds.load(\"qm9\", split=\"train\", as_supervised=False)\n",
    "print(qm9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab75aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:55:51.600749: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:396] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-11-21 18:55:57.540361: W tensorflow/core/kernels/data/cache_dataset_ops.cc:917] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Extracting data from dataset\n",
    "def extract_qm9_data(dataset, properties, max_samples=10000):\n",
    "    smiles_list = []\n",
    "    labels = []\n",
    "\n",
    "    for i, sample in enumerate(tfds.as_numpy(dataset)):\n",
    "        if i >= max_samples:\n",
    "            break\n",
    "\n",
    "        smiles = sample[\"SMILES\"].decode(\"utf-8\")\n",
    "        y = [sample[prop] for prop in properties]\n",
    "\n",
    "        smiles_list.append(smiles)\n",
    "        labels.append(y)\n",
    "\n",
    "    return smiles_list, labels\n",
    "\n",
    "# Target properties\n",
    "TARGET_PROPERTIES = [\"mu\", \"alpha\", \"gap\", \"Cv\", \"num_atoms\"]\n",
    "\n",
    "# Extracted data\n",
    "smiles, y = extract_qm9_data(qm9, TARGET_PROPERTIES, max_samples=5000)\n",
    "\n",
    "# Scaling target\n",
    "label_scaler = StandardScaler()\n",
    "y_scaled = label_scaler.fit_transform(y)\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(smiles, y_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38e3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize SMILES\n",
    "class QM9Dataset(Dataset):\n",
    "    def __init__(self, smiles, targets, tokenizer):\n",
    "        self.smiles = smiles\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.smiles[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].squeeze(),\n",
    "            'attention_mask': enc['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Load data into model\n",
    "class ChemBERTaMulti(torch.nn.Module):\n",
    "    def __init__(self, n_outputs):\n",
    "        super().__init__()\n",
    "        # Pre trained model\n",
    "        self.encoder = AutoModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "        # Head output\n",
    "        self.head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(768, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, n_outputs)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.head(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe732a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChemBERTaMulti(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(767, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "\n",
    "train_ds = QM9Dataset(X_train, y_train, tokenizer)\n",
    "test_ds = QM9Dataset(X_test, y_test, tokenizer)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "\n",
    "model = ChemBERTaMulti(n_outputs=len(TARGET_PROPERTIES))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8586af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "\n",
    "        preds = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "preds_all, true_all = [], []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        preds = model(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "        preds_all.append(preds.cpu().numpy())\n",
    "        true_all.append(labels.numpy())\n",
    "\n",
    "\n",
    "preds_all = np.vstack(preds_all)\n",
    "true_all = np.vstack(true_all)\n",
    "\n",
    "print(\"===== ChemBERTa Metrics =====\")\n",
    "for i, prop in enumerate(['mu', 'alpha', 'gap', 'Cv', 'num_atoms']):\n",
    "    mae = mean_absolute_error(true_all[:, i], preds_all[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(true_all[:, i], preds_all[:, i]))\n",
    "    r2 = r2_score(true_all[:, i], preds_all[:, i])\n",
    "    print(f\"{prop}: MAE={mae:.4f}, RMSE={rmse:.4f}, R2={r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
